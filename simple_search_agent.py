from langchain_community.tools import DuckDuckGoSearchRun
from langchain_groq import ChatGroq
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from dotenv import load_dotenv
import os

# Load environment variables from .env file
load_dotenv()

# Get API key from environment
GROQ_API_KEY = os.getenv("GROQ_API_KEY")

if not GROQ_API_KEY:
    raise ValueError(
        "GROQ_API_KEY not found in environment variables. Please check your .env file")

# Initialize the model
llm = ChatGroq(
    model="llama-3.1-8b-instant",
    temperature=0,
    groq_api_key=GROQ_API_KEY
)

# Initialize search
search = DuckDuckGoSearchRun()


def answer_question(question: str) -> str:
    """
    Answer a question using web search and LLM.

    Args:
        question (str): The question to answer

    Returns:
        str: The answer generated by the LLM based on search results
    """
    print(f"\nüîç Searching for information: {question}")

    try:
        # Perform search
        search_results = search.run(question)
        print(f"üìÑ Search results obtained")
    except Exception as e:
        print(f"‚ö†Ô∏è Search error: {e}")
        search_results = "Search failed"

    # Create prompt
    prompt = ChatPromptTemplate.from_messages([
        ("system", "You are a helpful assistant. Use the search results to answer questions accurately."),
        ("human",
         "Search Results:\n{search_results}\n\nQuestion: {question}\n\nAnswer:")
    ])

    # Create chain
    chain = prompt | llm | StrOutputParser()

    # Get answer
    answer = chain.invoke({
        "search_results": search_results,
        "question": question
    })

    return answer


# Usage
if __name__ == "__main__":
    question = "How many degrees are in a circle?"

    print("="*60)
    print("AI Assistant with Search")
    print("="*60)

    answer = answer_question(question)

    print(f"\n‚ùì Question: {question}")
    print(f"\n‚úÖ Answer:\n{answer}")
    print("\n" + "="*60)
